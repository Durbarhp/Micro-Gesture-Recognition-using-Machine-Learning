{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kq-hDludO9om",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c61b99-b9a2-43cf-efba-0064d8cd6b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "QbTYWnHGPnY_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, transforms=None):\n",
        "        self.imgs_path = '/content/drive/MyDrive/training/'\n",
        "        #self.imgs_path = 'training/'\n",
        "        file_list = glob.glob(self.imgs_path + \"*\")\n",
        "        print('Number of Class (folder) : ',len(file_list))\n",
        "        self.transforms = transforms\n",
        "        self.data = []\n",
        "        for class_path in file_list:\n",
        "            class_name = class_path.split(\"/\")[-1]\n",
        "            for img_path in glob.glob(class_path + \"/*.jpg\"):\n",
        "                self.data.append([img_path, class_name])\n",
        "        print('Number of file : ', len(self.data))\n",
        "        #self.class_map = {\"dogs\" : 0, \"cats\": 1}\n",
        "        self.class_map = {20:19, 21:20, 31:30, 32:31,\n",
        "                          1:0, 2:1, 28:27, 29:28,\n",
        "                          22:21, 23:22, 26:25, 24:23, 25:24, 27:26, 30:29,\n",
        "                          13:12, 12:11, 16:15, 17:16, 18:17, 14:13, 15:14, 19:18,\n",
        "                          3:2, 6:5, 8:8, 7:6, 9:8, 10:9, 11:10, 4:3, 5:4}\n",
        "\n",
        "        #self.class_map = {20:20, 21:21, 31:31, 32:32,\n",
        "        #                  1:1, 2:2, 28:28, 29:29,\n",
        "        #                  22:22, 23:23, 26:26, 24:24, 25:25, 27:27, 30:30,\n",
        "        #                  13:13, 12:12, 16:16, 17:17, 18:18, 14:14, 15:15, 19:19,\n",
        "        #                  3:3, 6:6, 8:8, 7:7, 9:9, 10:10, 11:11, 4:4, 5:5}\n",
        "        # self.class_map = {20:\"Body-moving to-torso\", 21:\"Body-Sitting-straightly\",31:\"Body-Shaking-shoulders\",\n",
        "        #                   1:\"Head-Turtle-Neck\", 2:\"Head-bulding-face-deep-breath\",28:\"Head-Head-up\",29:\"Head-Pressing-lips\",\n",
        "        #                   22:\"Hand-Touching-arms\",23:\"Hand-holding-hands\",26:\"Hand-manipulating-object\",24:\"Hand-Crossing-Finger\",25:\"Hand-Minaret-gesture\",27:\"Hand-Hold-back-arms\",30:\"Hand-Amrs-akimbo\",\n",
        "        #                   13:\"Body-Hand-Asjusting-hair\", 12:\"Body-Hand-Scratching-neck\", 16:\"Body-Hand-Scratching-back\", 17:\"Body-Hand-Folding-arms\", 18:\"Body-Hand-Dustoffing-closthes\",14:\"Body-Hand-Pulling-shirt-collar-xxx\",15:\"Body-Hand-covering-superasternal-notch\",19:\"Body-Hand-Putting-arms-behind-body\",\n",
        "        #                   3:\"Head-Hand:Touching-hat\",6:\"Head-Hand:Covering-face\",7:\"Head-Hand:Rubbing-eyes\",9:\"Head-Hand:Touching ears\", 10:\"Head-Hand:Bitting-nails\", 11:\"Head-Hand:Touching-Jaw\", 4:\"Head-Hand:Scratching-head\", 5:\"Head-Hand:Scratching-forehead\",8:\"Head-Hand:Scratching facial parts\"}\n",
        "        self.img_dim = (256, 256)\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, class_name = self.data[idx]\n",
        "        # print(img_path)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, self.img_dim)\n",
        "        #print('Len ClassMap : ', len(self.class_map),' Keys : ',self.class_map.keys())\n",
        "        class_id = self.class_map[int(class_name)]\n",
        "\n",
        "        img_tensor = torch.from_numpy(img)\n",
        "        img_tensor = img_tensor.permute(2, 0, 1).float()\n",
        "        class_id = torch.tensor([class_id])\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            img_tensor = self.transforms(img_tensor)\n",
        "\n",
        "        return img_tensor, class_id\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=32):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x) #30, 96, 50, 50\n",
        "        out = self.layer2(out)#30, 256, 24, 24\n",
        "        out = self.layer3(out)#30, 384, 24, 24\n",
        "        out = self.layer4(out)#30, 384, 24, 24\n",
        "        out = self.layer5(out)#30, 256, 11, 11\n",
        "        #out = self.avgpool(out)\n",
        "        #out = torch.flatten(out, 1)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        #print(out.shape)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        #print(out.shape)\n",
        "        return out\n",
        "\n",
        "###################\n",
        "### Load dataset\n",
        "###################\n",
        "\n",
        "transformations = transforms.Compose([transforms.Normalize((0,0,0), (1,1,1))])\n",
        "dataset     = CustomDataset(transformations)\n",
        "\n",
        "# Define the size of train and test splits\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "# Create random indices for train and test sets\n",
        "indices = list(range(len(dataset)))\n",
        "train_indices = indices[:train_size]\n",
        "test_indices = indices[train_size:]\n",
        "\n",
        "# Create DataLoader for train and test sets using SubsetRandomSampler\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "train_loader = DataLoader(dataset, batch_size=500, sampler=train_sampler, num_workers=4)\n",
        "print('Load Training data :: done')\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_indices)\n",
        "test_loader = DataLoader(dataset, batch_size=500, sampler=test_sampler, num_workers=4)\n",
        "print('Load Testing data :: done')\n",
        "\n",
        "###################\n",
        "### Training\n",
        "###################\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device :: ',device)\n",
        "\n",
        "# Parameters\n",
        "num_classes = 32\n",
        "num_epochs = 50\n",
        "learning_rate = 0.005\n",
        "\n",
        "model = AlexNet(num_classes).to(device)\n",
        "# print('Summary \\n', model)\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "# Load model\n",
        "PATH_SAVE ='/content/drive/MyDrive/training/chekpoint_Epoch_36.pth' #The saved path of saved epoch\n",
        "model.load_state_dict(torch.load(PATH_SAVE))\n",
        "model.eval()\n",
        "\n",
        "print('-------------------------------------------------------------------- Model loaded ')\n",
        "\n",
        "# Validation\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total   = 0\n",
        "    for images, labels in test_loader:\n",
        "      #print(images)\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      #print('Predict : ', predicted, '\\nCorrect : ',labels.squeeze())\n",
        "      correct += (predicted == labels.squeeze()).sum().item()\n",
        "      total += labels.size(0)\n",
        "\n",
        "      #plot images\n",
        "      #num_images = min(len(images), 3)  # Plot a maximum of 5 images\n",
        "      #fig, axes = plt.subplots(1, num_images, figsize=(12, 3))\n",
        "\n",
        "      # for i in range(num_images):\n",
        "      #     ax = axes[i] if num_images > 1 else axes  # Handle single image case\n",
        "      #     ax.imshow(images[i].cpu().numpy().transpose(1, 2, 0))  # Transpose to (H, W, C)\n",
        "      #     ax.set_title(f'Predicted: {predicted[i].item()}, Actual: {labels[i].item()}')\n",
        "      #     ax.axis('off')\n",
        "\n",
        "          # #plot images\n",
        "          # plt.imshow(images[0].permute(1, 2, 0) )\n",
        "          # plt.title('Target : '+str(labels[0])+' Predicted : '+str(predicted[0]))\n",
        "      # plt.show()\n",
        "\n",
        "      del images, labels, outputs\n",
        "\n",
        "    print ('Test accuracy: {:.4f}'\n",
        "               .format( 100 * correct / total))\n",
        "\n",
        "\n",
        "print('-------------------------------------------------------------------- Testing completed ')"
      ],
      "metadata": {
        "id": "zWXtWUInPo_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d111fd9-457e-4d0d-d325-d7540c5c310d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Class (folder) :  33\n",
            "Number of file :  56017\n",
            "Load Training data :: done\n",
            "Load Testing data :: done\n",
            "Device ::  cuda\n",
            "-------------------------------------------------------------------- Model loaded \n",
            "Test accuracy: 64.4680\n",
            "-------------------------------------------------------------------- Testing completed \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://blog.paperspace.com/alexnet-pytorch/"
      ],
      "metadata": {
        "id": "aAe1jE4VZIRW"
      }
    }
  ]
}